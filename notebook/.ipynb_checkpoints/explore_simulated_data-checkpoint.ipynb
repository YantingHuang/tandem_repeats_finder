{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the index of the simulated read for the case study and plot\n",
    "signal_index = 61\n",
    "simulation_data_run_name = \"test_sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/yantinghuang/Study/tandem_repeats_finder/\"\n",
    "align_dir = os.path.join(root_dir, simulation_data_run_name, \"align\")\n",
    "signal_dir = os.path.join(root_dir, simulation_data_run_name, \"signal\")\n",
    "output_dir = os.path.join(root_dir, 'data')\n",
    "\n",
    "align_fn = os.path.join(align_dir, f\"align_{signal_index}.ali\")\n",
    "signal_fn = os.path.join(signal_dir, f\"signal_{signal_index}.txt\")\n",
    "sampled_fa_fn = os.path.join(root_dir, simulation_data_run_name, \"sampled_read.fasta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load sampled fasta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/yantinghuang/Study/tandem_repeats_finder/sampled_read.fasta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bf2a8f241922>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcontain_tandem_repeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrepeats_start_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_fa_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/yantinghuang/Study/tandem_repeats_finder/sampled_read.fasta'"
     ]
    }
   ],
   "source": [
    "read_ind = []\n",
    "read_seq = []\n",
    "read_len = []\n",
    "contain_tandem_repeats = []\n",
    "repeats_start_end = []\n",
    "with open(sampled_fa_fn, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.startswith('>'):\n",
    "            read_ind.append(int(line.strip('\\n')[1:]))\n",
    "        else:\n",
    "            sampled_seq = line.strip('\\n')\n",
    "            read_seq.append(sampled_seq)\n",
    "            read_len.append(len(sampled_seq))\n",
    "            m = re.search(r\"(CGC){10,}\", sampled_seq)\n",
    "            if m:\n",
    "                contain_tandem_repeats.append(1)\n",
    "                repeats_start_end.append(m.span())\n",
    "            else:\n",
    "                contain_tandem_repeats.append(0)\n",
    "                repeats_start_end.append(())\n",
    "fasta_df = pd.DataFrame(data={'id': read_ind,\n",
    "                              'seq':read_seq,\n",
    "                              'seq_len': read_len,\n",
    "                              'contain_tandem_repeats': contain_tandem_repeats,\n",
    "                              'repeats_start_end': repeats_start_end})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fasta_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean length of simulated reads: {fasta_df.seq_len.mean()}\")\n",
    "print(f\"number of reads w/ tandem repeats: {fasta_df.contain_tandem_repeats.value_counts().loc[1]}\")\n",
    "print(f\"number of reads w/o tandem repeats: {fasta_df.contain_tandem_repeats.value_counts().loc[0]}\")\n",
    "print(fasta_df[fasta_df.contain_tandem_repeats==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fasta_df.seq_len, bins=len(fasta_df)//10, color = 'blue', edgecolor = 'black')\n",
    "plt.title('Read Length Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load align and signal file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "align_df = pd.read_csv(align_fn, sep=\" \", names=['signal_ind', 'base_ind'])\n",
    "signal_df = pd.read_csv(signal_fn, names=['signal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(align_df.base_ind.max())\n",
    "print(len(signal_df) == align_df.signal_ind.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(align_df.base_ind.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df['signal_ind'] = signal_df.index + 1\n",
    "signal_df = signal_df.merge(align_df, on='signal_ind', how='left')\n",
    "signal_combined_df = signal_df.groupby('base_ind').agg({'signal': 'mean'})\n",
    "signal_combined_df.reset_index(inplace = True)\n",
    "bases = [base for base in fasta_df.loc[fasta_df.id==signal_index, 'seq'].item()]\n",
    "signal_combined_df['base'] = bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = signal_combined_df['base_ind'].copy()\n",
    "y = signal_combined_df['signal'].copy()\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(20,20))\n",
    "\n",
    "# plot ax1\n",
    "ax1.plot(x, y, color='black')\n",
    "ymin = ax1.get_ylim()[0]\n",
    "if (fasta_df.repeats_start_end[signal_index]):\n",
    "    rep_start, rep_end = fasta_df.repeats_start_end[signal_index]\n",
    "    ax1.fill_between(x, ymin, y, \n",
    "                    where= (x >= rep_start+1) & (x <= rep_end),\n",
    "                    facecolor='red', \n",
    "                    alpha=0.5)\n",
    "ax1.set_title(\"signals in the simulated read\",\n",
    "              fontsize = 20)\n",
    "\n",
    "# plot ax2\n",
    "if (fasta_df.repeats_start_end[signal_index]):\n",
    "    ax2.plot(x, y, color='black', marker='o')\n",
    "    ymin = ax2.get_ylim()[0]\n",
    "    if (fasta_df.repeats_start_end[signal_index]):\n",
    "        rep_start, rep_end = fasta_df.repeats_start_end[signal_index]\n",
    "        ax2.fill_between(x, ymin, y, \n",
    "                        where= (x >= rep_start+1) & (x <= rep_end),\n",
    "                        facecolor='red', \n",
    "                     alpha=0.5)\n",
    "\n",
    "    \"\"\"\n",
    "    for coor, base in zip(list(zip(x, y)), signal_combined_df['base']):\n",
    "        label = base\n",
    "        ax2.annotate(label, # this is the text\n",
    "                     coor, # this is the point to label\n",
    "                     textcoords=\"offset points\", # how to position the text\n",
    "                     xytext=(0,10), # distance from text to points (x,y)\n",
    "                     ha='center') # horizontal alignment can be left, right or center\n",
    "    \"\"\"\n",
    "    border_dist = 10\n",
    "    ax2.set_xlim((rep_start+1-border_dist, rep_end+border_dist))\n",
    "    ax2.set_title(\"signals in the repeat region\",\n",
    "                  fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_ind = 8\n",
    "align_df.base_ind.value_counts()\n",
    "signal_ind = align_df.loc[align_df.base_ind==base_ind, 'signal_ind'].to_numpy()\n",
    "signal_ind = np.sort(signal_ind-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_df.iloc[signal_ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aln_fns = os.listdir(align_dir)\n",
    "read_indicies = [int(re.findall(r'\\d+', aln_fn)[0]) for aln_fn in all_aln_fns]\n",
    "read_indicies = sorted(read_indicies)\n",
    "print(f\"total num of simulated reads: {len(read_ind)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signal_label_arr(align_dir, signal_dir, read_indicies, fasta_df):\n",
    "    signals=[]\n",
    "    labels=[]\n",
    "    ind_label_dict = dict(zip(fasta_df['id'], fasta_df['contain_tandem_repeats']))\n",
    "    for ind in read_indicies:\n",
    "        align_fn = os.path.join(align_dir, f\"align_{ind}.ali\")\n",
    "        signal_fn = os.path.join(signal_dir, f\"signal_{ind}.txt\")\n",
    "        align_df = pd.read_csv(align_fn, sep=\" \", names=['signal_ind', 'base_ind'])\n",
    "        signal_df = pd.read_csv(signal_fn, names=['signal'])\n",
    "        signal_df['signal_ind'] = signal_df.index + 1\n",
    "        signal_df = signal_df.merge(align_df, on='signal_ind', how='left')\n",
    "        signal_combined_df = signal_df.groupby('base_ind').agg({'signal': 'mean'})\n",
    "        signal_combined_df.reset_index(inplace = True)\n",
    "        signal_combined_df.sort_values('base_ind', inplace=True)\n",
    "        signals.append(signal_combined_df['signal'].tolist())\n",
    "        labels.append(ind_label_dict.get(ind))\n",
    "        if (ind+1)%1000==0:\n",
    "            print(f\"{ind+1} simulated reads processed\")\n",
    "    max_seq_len = max([len(signal_vec) for signal_vec in signals])\n",
    "    num_signals = len(signals)\n",
    "    print(\"generating numpy array...\")\n",
    "    signals_arr = np.zeros((num_signals, max_seq_len), float)\n",
    "    for i in range(len(signals)):\n",
    "        signals_arr[i, 0:len(signals[i])] = signals[i]\n",
    "    labels_arr = np.array(labels).reshape(-1, 1)\n",
    "    data = np.concatenate((signals_arr, labels_arr), axis=1)\n",
    "    print(\"performing train-test split...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(signals_arr, \n",
    "                                                        labels_arr, \n",
    "                                                        train_size=0.75, \n",
    "                                                        stratify=labels_arr)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = generate_signal_label_arr(align_dir, signal_dir, read_indicies, fasta_df)\n",
    "train = np.concatenate([X_train, y_train], axis=1)\n",
    "test = np.concatenate([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump generated numpy array to csv\n",
    "train_fn = os.path.join(output_dir, \"train.csv\")\n",
    "test_fn = os.path.join(output_dir, \"test.csv\")\n",
    "\n",
    "np.savetxt(train_fn, train, delimiter=\",\")\n",
    "np.savetxt(test_fn, test, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
